{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = 'center'>Guessing Games</h1>\n",
    "<h3 align = 'center'>machine learning, one step at a time</h3>\n",
    "<h3 align = 'center'>Step 9. Exploration v. Exploitation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Exploration v. exploitation**\n",
    "\n",
    "_Reinforcment learning_ is a balancing act between __exploration__ and __exploitation__:\n",
    "\n",
    "- __Exploration__: where am I? what actions can I take? what happens when I take an action?\n",
    "- __Exploitation__: can I use my past knowledge of penalties and rewards to go in the right direction?\n",
    "\n",
    "We _explored_ the maze by randomly examining it many times. How can we _exploit_ those results to find our way quickly and easily?\n",
    "\n",
    "Let's go back to building our __q-table__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maze import Maze\n",
    "maze = Maze()\n",
    "\n",
    "# for this lesson, it will be easier if our sample\n",
    "# actions are 0,1,2,3 instead of N,S,E,W\n",
    "def sample(maze):\n",
    "    action = maze.sample()                    # this returns N,S,E,W\n",
    "    return maze.action_space().index(action)  # this converts to 0,1,2,3\n",
    "\n",
    "# run the maze lots of times; take note of every result in a q-table\n",
    "q = np.zeros((4,4,4))\n",
    "for n in range(3000):\n",
    "    state = maze.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = sample(maze)                        # return a random action (0,1,2,3)  \n",
    "        new_state, reward, done = maze.step(action)  # takes a step based upon the random action\n",
    "        q[state[0]][state[1]][action] += reward      # makes note of the resulting transition\n",
    "        state = new_state                            # ...and switches to the new state\n",
    "        \n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are typical results for (0,0), marked up, just to make things clear:\n",
    "<pre>\n",
    "state |   N  |  S  |  E  |   W\n",
    "(0,0) | -903.|  0. |  0. | -830.\n",
    "</pre>\n",
    "Around half the attempts ended right away, by going out of bounds (by stepping either north or west). Doesn't that seem a little wasteful?\n",
    "\n",
    "Or put another way: for any given state, if an action has resulted in penalties in the past, can we avoid that action in the future?\n",
    "\n",
    "We would like to use the q table to find our way, based on past results... but first! we need the awesome power of _argmax_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# here is an array of rewards...\n",
    "a = [-100,-200,0,-50]\n",
    "\n",
    "# I wish there was a function to tell me \n",
    "# the index of the entry that has the \n",
    "# maximum value... in this case, what is \n",
    "# the index of the entry with a value of \n",
    "# zero, indicating no penalties?\n",
    "\n",
    "# enter argmax! which return the index of \n",
    "# the maximum value. wow. just wow.\n",
    "print(np.argmax(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK good. Now that we have a fully populated __q-table__ and the awesome power of _argmax_, let's traverse the maze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is how we might take the first step...\n",
    "state = maze.reset()\n",
    "\n",
    "row = state[0]\n",
    "col = state[1]\n",
    "action = np.argmax(q[row][col])         # it's easier to use 0,1,2,3 instead of N,S,E,W for our action...\n",
    "state, reward, done = maze.step(action) # ...those values are interchangeable when calling step(action)\n",
    "print(maze.action_space()[action], state, reward, done)\n",
    "print(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a start... we will always take a first step that avoids a penalty.\n",
    "\n",
    "How about taking 10 steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = maze.reset()\n",
    "for n in range(10):\n",
    "    row = state[0]\n",
    "    col = state[1]\n",
    "    action = np.argmax(q[row][col])\n",
    "    state, reward, done = maze.step(action)\n",
    "    print(maze.action_space()[action], state, reward, done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... we avoided penalties. Unfortunately, we got caught in a loop, and did not go anywhere.\n",
    "\n",
    "What if we tried to balance __exploration__ and __exploitation__?\n",
    "\n",
    "For example, as a first attempt: what if we moved at random, but discarded moves that have penalties? (or more formally: what if we discard __transitions__ that have negative __q-values__)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "***Exercises***<p>\n",
    "- traverse the maze using random actions, but avoid actions with negative q-values\n",
    "- note! that won't work unless you allow the code, as provided, to populate a q-table in advance\n",
    "- see the guidance in the code sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from maze import Maze\n",
    "'''\n",
    "=== DO NOT CHANGE CODE STARTING HERE ====== POLICE LINE DO NOT CROSS ===========================\n",
    "'''\n",
    "maze = Maze()\n",
    "\n",
    "# convenient function to convert sample actions from N,S,E,W to 0,1,2,3\n",
    "def sample(maze):\n",
    "    action = maze.sample()                  \n",
    "    return maze.action_space().index(action)\n",
    "\n",
    "# build a q-table\n",
    "q = np.zeros((4,4,4))\n",
    "for n in range(10000):\n",
    "    state = maze.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = sample(maze)                        # return a random action (0,1,2,3)  \n",
    "        new_state, reward, done = maze.step(action)  # takes a step based upon the random action\n",
    "        q[state[0]][state[1]][action] += reward      # makes note of the resulting transition\n",
    "        state = new_state                            # ...and switches to the new state\n",
    "'''\n",
    "=== AND ENDING HERE ======================= POLICE LINE DO NOT CROSS ===========================\n",
    "'''\n",
    "\n",
    "###############################################################################\n",
    "#                                                                             #\n",
    "#  YOUR CODE GOES HERE...                                                     #\n",
    "#     ...something like                                                       #\n",
    "#             state = maze.reset()                                            #\n",
    "#             done = False                                                    #\n",
    "#             while not Done:                                                 #\n",
    "#                 get a sample action                                         #\n",
    "#                 while the q-value for the action is negative                #\n",
    "#                     get a different sample action                           #\n",
    "#                 use maze.step(action) to take step & update state           #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "print(maze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
